# Fine_Tune_llama
I fine-tuned a powerful language model using Unsloth, a high-performance library optimized for 4-bit model training and inference. The model I used was LLaMA 3 8B in 4-bit quantized format
